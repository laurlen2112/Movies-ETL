{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import re\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "# from config import db_password\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copy complete until step 6; once step 6 was completed there were 7037 rows, which is 4 more than the 7033 listed on 8.3.7 of the module.  Not sure where I went wrong. \n",
    "\n",
    "Before step 6, I had 7080 results, matching with module at 8.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Add the clean movie function that takes in the argument, \"movie\".\n",
    "# Added from lessons8.3.6 clean movies combine the earlier function with the new\n",
    "#merge columns function\n",
    "\n",
    "def clean_movie(movie):\n",
    "    movie = dict(movie) #create a non-destructive copy\n",
    "    alt_titles = {}\n",
    "    for key in ['Also known as','Arabic','Cantonese','Chinese','French',\n",
    "                'Hangul','Hebrew','Hepburn','Japanese','Literally',\n",
    "                'Mandarin','McCune–Reischauer','Original title','Polish',\n",
    "                'Revised Romanization','Romanized','Russian',\n",
    "                'Simplified','Traditional','Yiddish']:\n",
    "        if key in movie:\n",
    "            alt_titles[key] = movie[key]\n",
    "            movie.pop(key)\n",
    "    if len(alt_titles) > 0:\n",
    "        movie['alt_titles'] = alt_titles\n",
    "\n",
    "    # merge column names\n",
    "    def change_column_name(old_name, new_name):\n",
    "        if old_name in movie:\n",
    "            movie[new_name] = movie.pop(old_name)\n",
    "    change_column_name('Adaptation by', 'Writer(s)')\n",
    "    change_column_name('Country of origin', 'Country')\n",
    "    change_column_name('Directed by', 'Director')\n",
    "    change_column_name('Distributed by', 'Distributor')\n",
    "    change_column_name('Edited by', 'Editor(s)')\n",
    "    change_column_name('Length', 'Running time')\n",
    "    change_column_name('Original release', 'Release date')\n",
    "    change_column_name('Music by', 'Composer(s)')\n",
    "    change_column_name('Produced by', 'Producer(s)')\n",
    "    change_column_name('Producer', 'Producer(s)')\n",
    "    change_column_name('Productioncompanies ', 'Production company(s)')\n",
    "    change_column_name('Productioncompany ', 'Production company(s)')\n",
    "    change_column_name('Released', 'Release Date')\n",
    "    change_column_name('Release Date', 'Release date')\n",
    "    change_column_name('Screen story by', 'Writer(s)')\n",
    "    change_column_name('Screenplay by', 'Writer(s)')\n",
    "    change_column_name('Story by', 'Writer(s)')\n",
    "    change_column_name('Theme music composer', 'Composer(s)')\n",
    "    change_column_name('Written by', 'Writer(s)')\n",
    "\n",
    "    return movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete later: create file path for testing\n",
    "\n",
    "# 6 Create the path to your file directory and variables for the three files. \n",
    "file_dir = os.path.join(\"../Movies-ETL\")\n",
    "# Wikipedia data\n",
    "wiki_file = f'{file_dir}/wikipedia_movies.json'\n",
    "# Kaggle metadata\n",
    "kaggle_file = f'{file_dir}/movies_metadata.csv'\n",
    "# MovieLens rating data.\n",
    "ratings_file = f'{file_dir}/ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2 testing block\n",
    "\n",
    "def ETL():\n",
    "    \n",
    "    # 2. Read in the kaggle metadata and MovieLens ratings CSV files as Pandas DataFrames.\n",
    "    kaggle_file = pd.read_csv('movies_metadata.csv', low_memory = False)\n",
    "    ratings_file = pd.read_csv('ratings.csv', low_memory = False)\n",
    "\n",
    "    # 3. Open the read the Wikipedia data JSON file.\n",
    "    with open(f'{file_dir}/wikipedia_movies.json', mode='r') as file:\n",
    "        wiki_movies = json.load(file)\n",
    "    \n",
    "     # 3. Write a list comprehension to filter out TV shows.\n",
    "    wiki_file = [movie for movie in wiki_movies\n",
    "              if('Director' in movie or 'Directed by' in movie)\n",
    "              and 'imdb_link' in movie\n",
    "              and \"no. of episodes\" not in movie]\n",
    "     # 4. Write a list comprehension to iterate through the cleaned wiki movies list\n",
    "    # and call the clean_movie function on each movie.\n",
    "    clean_movies = [clean_movie(movie) for movie in wiki_file]\n",
    "    \n",
    "    # 5. Read in the cleaned movies list from Step 4 as a DataFrame.\n",
    "    clean_wiki_df = pd.DataFrame(clean_movies)\n",
    "    sorted(clean_wiki_df.columns.tolist())\n",
    "    \n",
    "    # 6. Write a try-except block to catch errors while extracting the IMDb ID using a regular expression string and\n",
    "    #  dropping any imdb_id duplicates. If there is an error, capture and print the exception.\n",
    "    try:\n",
    "        clean_wiki_df['imdb_id'] = clean_wiki_df['imdb_link'].str.extract(r'(tt\\d{7})')\n",
    "        clean_wiki_df.drop_duplicates(subset='imdb_id', inplace=True)\n",
    "        \n",
    "    except(IndexError):\n",
    "        print('Index Error .... skipping')   \n",
    "        \n",
    "        \n",
    "    #  7. Write a list comprehension to keep the columns that don't have null values from the wiki_movies_df DataFrame.\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    return clean_wiki_df, kaggle_file, ratings_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function tested to step 5, len 7080 and returns a .head & .tail; both CSV are type = DF\n",
    "# works up to step 6 len(clean_wiki_df = 7037 which is 4 more than module 8.3.7)\n",
    "clean_wiki_df, kaggle_file, ratings_file = ETL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7037"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_wiki_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['url', 0],\n",
       " ['year', 0],\n",
       " ['imdb_link', 0],\n",
       " ['title', 1],\n",
       " ['Based on', 4855],\n",
       " ['Starring', 185],\n",
       " ['Narrated by', 6755],\n",
       " ['Cinematography', 693],\n",
       " ['Release date', 32],\n",
       " ['Running time', 139],\n",
       " ['Country', 236],\n",
       " ['Language', 248],\n",
       " ['Budget', 2298],\n",
       " ['Box office', 1552],\n",
       " ['Director', 0],\n",
       " ['Distributor', 360],\n",
       " ['Editor(s)', 548],\n",
       " ['Composer(s)', 519],\n",
       " ['Producer(s)', 203],\n",
       " ['Production company(s)', 1678],\n",
       " ['Writer(s)', 201],\n",
       " ['Genre', 6923],\n",
       " ['Original language(s)', 6875],\n",
       " ['Original network', 6908],\n",
       " ['Executive producer(s)', 6937],\n",
       " ['Production location(s)', 6987],\n",
       " ['Picture format', 6969],\n",
       " ['Audio format', 6973],\n",
       " ['Voices of', 7035],\n",
       " ['Followed by', 7028],\n",
       " ['Created by', 7026],\n",
       " ['Opening theme', 7036],\n",
       " ['No. of episodes', 7033],\n",
       " ['alt_titles', 7015],\n",
       " ['Preceded by', 7027],\n",
       " ['Suggested by', 7036],\n",
       " ['Recorded', 7035],\n",
       " ['Venue', 7036],\n",
       " ['Label', 7035],\n",
       " ['Animation by', 7035],\n",
       " ['Color process', 7036],\n",
       " ['Camera setup', 7036],\n",
       " ['McCune–Reischauer', 7035],\n",
       " ['imdb_id', 0]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check null columns\n",
    "[[column,clean_wiki_df[column].isnull().sum()] for column in clean_wiki_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7037 entries, 0 to 7079\n",
      "Data columns (total 44 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   url                     7037 non-null   object\n",
      " 1   year                    7037 non-null   int64 \n",
      " 2   imdb_link               7037 non-null   object\n",
      " 3   title                   7036 non-null   object\n",
      " 4   Based on                2182 non-null   object\n",
      " 5   Starring                6852 non-null   object\n",
      " 6   Narrated by             282 non-null    object\n",
      " 7   Cinematography          6344 non-null   object\n",
      " 8   Release date            7005 non-null   object\n",
      " 9   Running time            6898 non-null   object\n",
      " 10  Country                 6801 non-null   object\n",
      " 11  Language                6789 non-null   object\n",
      " 12  Budget                  4739 non-null   object\n",
      " 13  Box office              5485 non-null   object\n",
      " 14  Director                7037 non-null   object\n",
      " 15  Distributor             6677 non-null   object\n",
      " 16  Editor(s)               6489 non-null   object\n",
      " 17  Composer(s)             6518 non-null   object\n",
      " 18  Producer(s)             6834 non-null   object\n",
      " 19  Production company(s)   5359 non-null   object\n",
      " 20  Writer(s)               6836 non-null   object\n",
      " 21  Genre                   114 non-null    object\n",
      " 22  Original language(s)    162 non-null    object\n",
      " 23  Original network        129 non-null    object\n",
      " 24  Executive producer(s)   100 non-null    object\n",
      " 25  Production location(s)  50 non-null     object\n",
      " 26  Picture format          68 non-null     object\n",
      " 27  Audio format            64 non-null     object\n",
      " 28  Voices of               2 non-null      object\n",
      " 29  Followed by             9 non-null      object\n",
      " 30  Created by              11 non-null     object\n",
      " 31  Opening theme           1 non-null      object\n",
      " 32  No. of episodes         4 non-null      object\n",
      " 33  alt_titles              22 non-null     object\n",
      " 34  Preceded by             10 non-null     object\n",
      " 35  Suggested by            1 non-null      object\n",
      " 36  Recorded                2 non-null      object\n",
      " 37  Venue                   1 non-null      object\n",
      " 38  Label                   2 non-null      object\n",
      " 39  Animation by            2 non-null      object\n",
      " 40  Color process           1 non-null      object\n",
      " 41  Camera setup            1 non-null      object\n",
      " 42  McCune–Reischauer       2 non-null      object\n",
      " 43  imdb_id                 7037 non-null   object\n",
      "dtypes: int64(1), object(43)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_wiki_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7080"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_wiki_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_wiki_one = clean_wiki_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7080"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_wiki_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7080 entries, 0 to 7079\n",
      "Data columns (total 43 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   url                     7080 non-null   object\n",
      " 1   year                    7080 non-null   int64 \n",
      " 2   imdb_link               7080 non-null   object\n",
      " 3   title                   7079 non-null   object\n",
      " 4   Based on                2191 non-null   object\n",
      " 5   Starring                6895 non-null   object\n",
      " 6   Narrated by             283 non-null    object\n",
      " 7   Cinematography          6380 non-null   object\n",
      " 8   Release date            7048 non-null   object\n",
      " 9   Running time            6940 non-null   object\n",
      " 10  Country                 6841 non-null   object\n",
      " 11  Language                6832 non-null   object\n",
      " 12  Budget                  4765 non-null   object\n",
      " 13  Box office              5517 non-null   object\n",
      " 14  Director                7080 non-null   object\n",
      " 15  Distributor             6718 non-null   object\n",
      " 16  Editor(s)               6529 non-null   object\n",
      " 17  Composer(s)             6560 non-null   object\n",
      " 18  Producer(s)             6877 non-null   object\n",
      " 19  Production company(s)   5392 non-null   object\n",
      " 20  Writer(s)               6879 non-null   object\n",
      " 21  Genre                   114 non-null    object\n",
      " 22  Original language(s)    162 non-null    object\n",
      " 23  Original network        129 non-null    object\n",
      " 24  Executive producer(s)   100 non-null    object\n",
      " 25  Production location(s)  50 non-null     object\n",
      " 26  Picture format          68 non-null     object\n",
      " 27  Audio format            64 non-null     object\n",
      " 28  Voices of               2 non-null      object\n",
      " 29  Followed by             9 non-null      object\n",
      " 30  Created by              11 non-null     object\n",
      " 31  Opening theme           1 non-null      object\n",
      " 32  No. of episodes         4 non-null      object\n",
      " 33  alt_titles              22 non-null     object\n",
      " 34  Preceded by             10 non-null     object\n",
      " 35  Suggested by            1 non-null      object\n",
      " 36  Recorded                2 non-null      object\n",
      " 37  Venue                   1 non-null      object\n",
      " 38  Label                   2 non-null      object\n",
      " 39  Animation by            2 non-null      object\n",
      " 40  Color process           1 non-null      object\n",
      " 41  Camera setup            1 non-null      object\n",
      " 42  McCune–Reischauer       2 non-null      object\n",
      "dtypes: int64(1), object(42)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_wiki_one.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Add the function that takes in three arguments;\n",
    "# Wikipedia data, Kaggle metadata, and MovieLens rating data (from Kaggle)\n",
    "## from Del 1\n",
    "def ETL():\n",
    "    \n",
    "    # 2. Read in the kaggle metadata and MovieLens ratings CSV files as Pandas DataFrames.\n",
    "    #kaggle_file = pd.read_csv('movies_metadata.csv', low_memory = False)\n",
    "    #ratings_file = pd.read_csv('ratings.csv', low_memory = False)\n",
    "\n",
    "    # 3. Open the read the Wikipedia data JSON file.\n",
    "    with open(f'{file_dir}/wikipedia_movies.json', mode='r') as file:\n",
    "        wiki_movies = json.load(file)\n",
    "    \n",
    "     # 3. Write a list comprehension to filter out TV shows.\n",
    "    wiki_file = [movie for movie in wiki_movies\n",
    "              if('Director' in movie or 'Directed by' in movie)\n",
    "              and 'imdb_link' in movie\n",
    "              and \"no. of episodes\" not in movie]\n",
    "\n",
    "    # 4. Write a list comprehension to iterate through the cleaned wiki movies list\n",
    "    # and call the clean_movie function on each movie.\n",
    "    clean_movies = [clean_movie(movie) for movie in wiki_file]\n",
    "\n",
    "    # 5. Read in the cleaned movies list from Step 4 as a DataFrame.\n",
    "    #clean_wiki_df = pd.DataFrame(clean_movies)\n",
    "   # sorted(wiki_movies_df.columns.tolist())\n",
    "    # 6. Write a try-except block to catch errors while extracting the IMDb ID using a regular expression string and\n",
    "    #  dropping any imdb_id duplicates. If there is an error, capture and print the exception.\n",
    "   # try:\n",
    "        \n",
    "  #  except \n",
    "\n",
    "    #  7. Write a list comprehension to keep the columns that don't have null values from the wiki_movies_df DataFrame.\n",
    "    \n",
    "\n",
    "    # 8. Create a variable that will hold the non-null values from the “Box office” column.\n",
    "\n",
    "    \n",
    "    # 9. Convert the box office data created in Step 8 to string values using the lambda and join functions.\n",
    "    \n",
    "\n",
    "    # 10. Write a regular expression to match the six elements of \"form_one\" of the box office data.\n",
    "   \n",
    "   # 11. Write a regular expression to match the three elements of \"form_two\" of the box office data.\n",
    "    \n",
    "\n",
    "    # 12. Add the parse_dollars function.\n",
    "    \n",
    "    \n",
    "        \n",
    "    # 13. Clean the box office column in the wiki_movies_df DataFrame.\n",
    "\n",
    "    \n",
    "    # 14. Clean the budget column in the wiki_movies_df DataFrame.\n",
    "    \n",
    "\n",
    "    # 15. Clean the release date column in the wiki_movies_df DataFrame.\n",
    "    \n",
    "\n",
    "    # 16. Clean the running time column in the wiki_movies_df DataFrame.\n",
    "    \n",
    "    # Return three variables. The first is the wiki_movies_df DataFrame\n",
    "    \n",
    "    return wiki_file\n",
    "                 #clean_wiki_df #kaggle_file, ratings_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Create the path to your file directory and variables for the three files.\n",
    "# 6 Create the path to your file directory and variables for the three files. \n",
    "file_dir = os.path.join(\"../Movies-ETL\")\n",
    "# Wikipedia data\n",
    "wiki_file = f'{file_dir}/wikipedia_movies.json'\n",
    "# Kaggle metadata\n",
    "kaggle_file = f'{file_dir}/movies_metadata.csv'\n",
    "# MovieLens rating data.\n",
    "ratings_file = f'{file_dir}/ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. Set the three variables equal to the function created in D1.\n",
    "##changed func name to match with mine\n",
    "wiki_file, kaggle_file, ratings_file = ETL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19. Set the wiki_movies_df equal to the wiki_file variable. \n",
    "wiki_movies_df = wiki_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20. Check that the wiki_movies_df DataFrame looks like this. \n",
    "wiki_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21. Check that wiki_movies_df DataFrame columns are correct. \n",
    "wiki_movies_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
